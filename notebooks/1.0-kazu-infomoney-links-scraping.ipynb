{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infomoney Links Scraping\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making the necessary imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "from datetime import datetime\n",
    "from typing import Any\n",
    "from xml.etree.ElementTree import Element\n",
    "\n",
    "from scrapy import Request\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "from scrapy.spiders import Spider"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instanciating a scrapy spider called `BigSpooder`, and sending it to the infomoney sitemap index `xml`.\n",
    "\n",
    "After that, we are going trough all other links that send to another sitemap regarding news and that are around the time span after September 2022.\n",
    "\n",
    "During this process we are writing a csv file containg all the links.\n",
    "\n",
    "> In future instances we could directly send this to be treated and scraped or store it in a DB, for educational purposes we are separating the link scraping process and the news scraping process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigSpooder(Spider):\n",
    "    name: str = \"BigSpooder\"  # Spider's name\n",
    "    # Site to be crawled\n",
    "    start_urls: list[str] = [\"https://www.infomoney.com.br/sitemap_index.xml\"]\n",
    "    namespaces: dict[str, str] = {\n",
    "        \"xmlns\": \"http://www.sitemaps.org/schemas/sitemap/0.9\"\n",
    "    }\n",
    "\n",
    "    def parse(self, response):\n",
    "        xmlns: Any = (\n",
    "            response.xpath(\"//xmlns:sitemap\", namespaces=self.namespaces)\n",
    "        ).getall()\n",
    "        for sitemap in xmlns:\n",
    "            xml: Element = ET.fromstring(sitemap)\n",
    "            loc: str | None = xml.find(f\"{{{ self.namespaces['xmlns'] }}}loc\").text\n",
    "            lastmod: str | None = xml.find(\n",
    "                f\"{{{ self.namespaces['xmlns'] }}}lastmod\"\n",
    "            ).text\n",
    "            date: datetime = datetime.strptime(lastmod, \"%Y-%m-%dT%H:%M:%S%z\")\n",
    "            if (\n",
    "                date.year == 2022 and date.month >= 9 or date.year == 2023\n",
    "            ) and re.match(\".*(/post-sitemap\\d*.xml)$\", loc):\n",
    "                yield Request(loc, callback=self.getLinks)\n",
    "\n",
    "    def getLinks(self, response):\n",
    "        self.logger.info(\"we hot\")\n",
    "        xmlns: Any = (\n",
    "            response.xpath(\"//xmlns:url\", namespaces=self.namespaces)\n",
    "        ).getall()\n",
    "        for sitemap in xmlns:\n",
    "            xml: Element = ET.fromstring(sitemap)\n",
    "            loc: str | None = xml.find(f\"{{{ self.namespaces['xmlns'] }}}loc\").text\n",
    "            lastmod: str | None = xml.find(\n",
    "                f\"{{{ self.namespaces['xmlns'] }}}lastmod\"\n",
    "            ).text\n",
    "            date: datetime = datetime.strptime(lastmod, \"%Y-%m-%dT%H:%M:%S%z\")\n",
    "            if date.year >= 2022:\n",
    "                yield {\"link\": loc}\n",
    "\n",
    "\n",
    "# Settings do processo\n",
    "process: Any = CrawlerProcess(\n",
    "    settings={\n",
    "        \"FEEDS\": {\"infomoney-links.csv\": {\"format\": \"csv\"}},\n",
    "        \"REQUEST_FINGERPRINTER_IMPLEMENTATION\": \"2.7\",\n",
    "    }\n",
    ")\n",
    "process.crawl(BigSpooder)\n",
    "process.start()\n",
    "\n",
    "# Because of the way that the library works, if we want to run the spider again we must restart the kernel"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
